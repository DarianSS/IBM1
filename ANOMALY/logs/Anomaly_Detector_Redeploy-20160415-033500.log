Deploy script started at Fri Apr 15 03:35:00 EEST 2016
Running /users/Darian/PredictionIO-0.9.6//bin/pio train --verbose -v engine.json -- --executor-memory 16G --driver-memory 8G --total-executor-cores 4
[INFO] [Console$] Using existing engine manifest JSON at /Users/darian/PredictionIO-0.9.6/templates/ANOMALY/manifest.json
[DEBUG] [ConnectionPool$] Registered connection pool : ConnectionPool(url:jdbc:postgresql://localhost/pio, user:darian) using factory : <default>
[DEBUG] [ConnectionPool$] Registered singleton connection pool : ConnectionPool(url:jdbc:postgresql://localhost/pio, user:darian)
[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   create table if not exists pio_meta_enginemanifests ( id varchar(100) not null primary key, version text not null, engineName text not null, description text, files text not null, engineFactory text not null); (2 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCEngineManifests$$anonfun$1.apply(JDBCEngineManifests.scala:37)
    io.prediction.data.storage.jdbc.JDBCEngineManifests$$anonfun$1.apply(JDBCEngineManifests.scala:29)
    scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:222)
    scalikejdbc.DB.autoCommit(DB.scala:60)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:214)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.autoCommit(DB.scala:214)
    io.prediction.data.storage.jdbc.JDBCEngineManifests.<init>(JDBCEngineManifests.scala:29)
    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    java.lang.reflect.Constructor.newInstance(Constructor.java:408)
    io.prediction.data.storage.Storage$.getDataObject(Storage.scala:303)
    ...

[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   SELECT id, version, engineName, description, files, engineFactory FROM pio_meta_enginemanifests WHERE id = 'ulP05G3N7mAwusAYQ5cN1hrLFaDS1xwp' AND version = 'd3b3dc43fd7f00c3c7d9ac56b2678b6ad6396624'; (13 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCEngineManifests$$anonfun$3.apply(JDBCEngineManifests.scala:61)
    io.prediction.data.storage.jdbc.JDBCEngineManifests$$anonfun$3.apply(JDBCEngineManifests.scala:51)
    scalikejdbc.DBConnection$$anonfun$3.apply(DBConnection.scala:305)
    scalikejdbc.DBConnection$class.scalikejdbc$DBConnection$$rollbackIfThrowable(DBConnection.scala:274)
    scalikejdbc.DBConnection$class.localTx(DBConnection.scala:303)
    scalikejdbc.DB.localTx(DB.scala:60)
    scalikejdbc.DB$.localTx(DB.scala:257)
    io.prediction.data.storage.jdbc.JDBCEngineManifests.get(JDBCEngineManifests.scala:51)
    io.prediction.tools.console.Console$.withRegisteredManifest(Console.scala:1214)
    io.prediction.tools.console.Console$.train(Console.scala:839)
    io.prediction.tools.console.Console$$anonfun$main$1.apply(Console.scala:713)
    io.prediction.tools.console.Console$$anonfun$main$1.apply(Console.scala:693)
    scala.Option.map(Option.scala:145)
    io.prediction.tools.console.Console$.main(Console.scala:693)
    io.prediction.tools.console.Console.main(Console.scala)
    ...

[INFO] [Runner$] Submission command: /users/Darian/PredictionIO-0.9.6/vendors/spark-1.5.1/bin/spark-submit --executor-memory 16G --driver-memory 8G --total-executor-cores 4 --class io.prediction.workflow.CreateWorkflow --jars file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/target/scala-2.10/barebone-template-assembly-0.1-SNAPSHOT-deps.jar,file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/target/scala-2.10/barebone-template_2.10-0.1-SNAPSHOT.jar --files file:/users/Darian/PredictionIO-0.9.6/conf/log4j.properties,file:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf/hbase-site.xml --driver-class-path /users/Darian/PredictionIO-0.9.6/conf:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf file:/users/Darian/PredictionIO-0.9.6/lib/pio-assembly-0.9.6.jar --engine-id ulP05G3N7mAwusAYQ5cN1hrLFaDS1xwp --engine-version d3b3dc43fd7f00c3c7d9ac56b2678b6ad6396624 --engine-variant file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/engine.json --verbosity 0 --verbose --json-extractor Both --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_meta,PIO_FS_BASEDIR=/Users/darian/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0,PIO_HOME=/users/Darian/PredictionIO-0.9.6,PIO_FS_ENGINESDIR=/Users/darian/.pio_store/engines,PIO_STORAGE_SOURCES_LOCALFS_PATH=/Users/darian/.pio_store/models,PIO_STORAGE_SOURCES_PGSQL_URL=jdbc:postgresql://localhost/pio,PIO_STORAGE_SOURCES_HDFS_TYPE=hdfs,PIO_STORAGE_SOURCES_HDFS_PATH=/Users/darian/.pio_store/models,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=PGSQL,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=PGSQL,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=pio_event,PIO_STORAGE_SOURCES_PGSQL_PASSWORD=,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/users/Darian/PredictionIO-0.9.6/vendors/elasticsearch-1.4.4,PIO_STORAGE_SOURCES_PGSQL_TYPE=jdbc,PIO_FS_TMPDIR=/Users/darian/.pio_store/tmp,PIO_STORAGE_SOURCES_PGSQL_USERNAME=darian,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_model,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=PGSQL,PIO_CONF_DIR=/users/Darian/PredictionIO-0.9.6/conf,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --verbose
Warning: Unknown option --verbose
[DEBUG] [] address: Darians-MacBook.local/192.168.0.3 isLoopbackAddress: false, with host 192.168.0.3 Darians-MacBook.local
[INFO] [Engine] Extracting datasource params...
[INFO] [WorkflowUtils$] No 'name' is found. Default empty String will be used.
[INFO] [Engine] Datasource params: (,ucl.team10.anomaly.DataSourceParams@3a4e343)
[INFO] [Engine] Extracting preparator params...
[INFO] [Engine] Preparator params: (,Empty)
[INFO] [Engine] Extracting serving params...
[INFO] [Engine] Serving params: (,Empty)
[DEBUG] [ConnectionPool$] Registered connection pool : ConnectionPool(url:jdbc:postgresql://localhost/pio, user:darian) using factory : <default>
[DEBUG] [ConnectionPool$] Registered singleton connection pool : ConnectionPool(url:jdbc:postgresql://localhost/pio, user:darian)
[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   create table if not exists pio_meta_engineinstances ( id varchar(100) not null primary key, status text not null, startTime timestamp DEFAULT CURRENT_TIMESTAMP, endTime timestamp DEFAULT CURRENT_TIMESTAMP, engineId text not null, engineVersion text not null, engineVariant text not null, engineFactory text not null, batch text not null, env text not null, sparkConf text not null, datasourceParams text not null, preparatorParams text not null, algorithmsParams text not null, servingParams text not null); (2 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$1.apply(JDBCEngineInstances.scala:46)
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$1.apply(JDBCEngineInstances.scala:29)
    scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:222)
    scalikejdbc.DB.autoCommit(DB.scala:60)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:214)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.autoCommit(DB.scala:214)
    io.prediction.data.storage.jdbc.JDBCEngineInstances.<init>(JDBCEngineInstances.scala:29)
    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    java.lang.reflect.Constructor.newInstance(Constructor.java:408)
    io.prediction.data.storage.Storage$.getDataObject(Storage.scala:303)
    ...

[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   INSERT INTO pio_meta_engineinstances VALUES( '1c9f0a71-e563-4ed1-8317-c27e3b795c80', 'INIT', '2016-04-15 03:35:04.059', '2016-04-15 03:35:04.061', 'ulP05G3N7mAwusAYQ5cN1hrLFaDS1xwp', 'd3b3dc43fd7f00c3c7d9ac56b2678b6ad6396624', 'default', 'ucl.team10.anomaly.AnomalyEngine', '', 'PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_met... (1246)', 'spark.executor.extraClassPath=.', '{"":{"appName":"ESB"}}', '{"":{}}', '[{"algo":{"degree":3,"gamma":0.25,"coef0":0.0,"nu":0.5,"cache_size":100.0,"eps":0.001,"C":1.0,"p":0.... (148)', '{"":{}}'); (2 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$2.apply(JDBCEngineInstances.scala:67)
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$2.apply(JDBCEngineInstances.scala:49)
    scalikejdbc.DBConnection$$anonfun$3.apply(DBConnection.scala:305)
    scalikejdbc.DBConnection$class.scalikejdbc$DBConnection$$rollbackIfThrowable(DBConnection.scala:274)
    scalikejdbc.DBConnection$class.localTx(DBConnection.scala:303)
    scalikejdbc.DB.localTx(DB.scala:60)
    scalikejdbc.DB$.localTx(DB.scala:257)
    io.prediction.data.storage.jdbc.JDBCEngineInstances.insert(JDBCEngineInstances.scala:49)
    io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:244)
    io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    java.lang.reflect.Method.invoke(Method.java:483)
    org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)
    ...

[DEBUG] [CoreWorkflow$] Starting SparkContext
[DEBUG] [WorkflowContext$] Executor environment received: Map(PIO_STORAGE_SOURCES_HBASE_TYPE -> hbase, PIO_ENV_LOADED -> 1, PIO_STORAGE_REPOSITORIES_METADATA_NAME -> pio_meta, PIO_FS_BASEDIR -> /Users/darian/.pio_store, PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS -> localhost, PIO_STORAGE_SOURCES_HBASE_HOME -> /users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0, PIO_HOME -> /users/Darian/PredictionIO-0.9.6, PIO_FS_ENGINESDIR -> /Users/darian/.pio_store/engines, PIO_STORAGE_SOURCES_LOCALFS_PATH -> /Users/darian/.pio_store/models, PIO_STORAGE_SOURCES_PGSQL_URL -> jdbc:postgresql://localhost/pio, PIO_STORAGE_SOURCES_HDFS_TYPE -> hdfs, PIO_STORAGE_SOURCES_HDFS_PATH -> /Users/darian/.pio_store/models, PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE -> elasticsearch, PIO_STORAGE_REPOSITORIES_METADATA_SOURCE -> PGSQL, PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE -> PGSQL, PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME -> pio_event, PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME -> /users/Darian/PredictionIO-0.9.6/vendors/elasticsearch-1.4.4, PIO_STORAGE_SOURCES_PGSQL_TYPE -> jdbc, PIO_FS_TMPDIR -> /Users/darian/.pio_store/tmp, PIO_STORAGE_SOURCES_PGSQL_USERNAME -> darian, PIO_STORAGE_REPOSITORIES_MODELDATA_NAME -> pio_model, PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE -> PGSQL, PIO_CONF_DIR -> /users/Darian/PredictionIO-0.9.6/conf, PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS -> 9300, PIO_STORAGE_SOURCES_LOCALFS_TYPE -> localfs)
[DEBUG] [WorkflowContext$] SparkConf executor environment: ArraySeq((PIO_STORAGE_SOURCES_PGSQL_URL,jdbc:postgresql://localhost/pio), (PIO_STORAGE_REPOSITORIES_METADATA_NAME,pio_meta), (PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME,pio_event), (PIO_STORAGE_SOURCES_HBASE_TYPE,hbase), (PIO_STORAGE_REPOSITORIES_METADATA_SOURCE,PGSQL), (PIO_STORAGE_SOURCES_PGSQL_TYPE,jdbc), (PIO_STORAGE_SOURCES_PGSQL_USERNAME,darian), (PIO_STORAGE_SOURCES_HBASE_HOME,/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0), (PIO_ENV_LOADED,1), (PIO_FS_TMPDIR,/Users/darian/.pio_store/tmp), (PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME,/users/Darian/PredictionIO-0.9.6/vendors/elasticsearch-1.4.4), (PIO_FS_ENGINESDIR,/Users/darian/.pio_store/engines), (PIO_STORAGE_SOURCES_LOCALFS_TYPE,localfs), (PIO_CONF_DIR,/users/Darian/PredictionIO-0.9.6/conf), (PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE,elasticsearch), (PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE,PGSQL), (PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS,9300), (PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS,localhost), (PIO_STORAGE_REPOSITORIES_MODELDATA_NAME,pio_model), (PIO_STORAGE_SOURCES_HDFS_TYPE,hdfs), (PIO_FS_BASEDIR,/Users/darian/.pio_store), (PIO_STORAGE_SOURCES_HDFS_PATH,/Users/darian/.pio_store/models), (PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE,PGSQL), (PIO_STORAGE_SOURCES_LOCALFS_PATH,/Users/darian/.pio_store/models), (PIO_HOME,/users/Darian/PredictionIO-0.9.6))
[DEBUG] [WorkflowContext$] Application environment received: Map(spark.executor.extraClassPath -> .)
[DEBUG] [WorkflowContext$] SparkConf environment: WrappedArray((spark.executorEnv.PIO_STORAGE_SOURCES_PGSQL_URL,jdbc:postgresql://localhost/pio), (spark.files,file:/users/Darian/PredictionIO-0.9.6/conf/log4j.properties,file:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf/hbase-site.xml), (spark.executorEnv.PIO_STORAGE_REPOSITORIES_METADATA_NAME,pio_meta), (spark.executorEnv.PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME,pio_event), (spark.executorEnv.PIO_STORAGE_SOURCES_HBASE_TYPE,hbase), (spark.executor.extraClassPath,.), (spark.executorEnv.PIO_STORAGE_REPOSITORIES_METADATA_SOURCE,PGSQL), (spark.executorEnv.PIO_STORAGE_SOURCES_PGSQL_TYPE,jdbc), (spark.executorEnv.PIO_STORAGE_SOURCES_PGSQL_USERNAME,darian), (spark.executorEnv.PIO_STORAGE_SOURCES_HBASE_HOME,/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0), (spark.executorEnv.PIO_ENV_LOADED,1), (spark.app.name,PredictionIO Training: ucl.team10.anomaly.AnomalyEngine), (spark.master,local[*]), (spark.executorEnv.PIO_FS_TMPDIR,/Users/darian/.pio_store/tmp), (spark.submit.deployMode,client), (spark.executorEnv.PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME,/users/Darian/PredictionIO-0.9.6/vendors/elasticsearch-1.4.4), (spark.executorEnv.PIO_FS_ENGINESDIR,/Users/darian/.pio_store/engines), (spark.executorEnv.PIO_STORAGE_SOURCES_LOCALFS_TYPE,localfs), (spark.executorEnv.PIO_CONF_DIR,/users/Darian/PredictionIO-0.9.6/conf), (spark.executorEnv.PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE,elasticsearch), (spark.jars,file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/target/scala-2.10/barebone-template-assembly-0.1-SNAPSHOT-deps.jar,file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/target/scala-2.10/barebone-template_2.10-0.1-SNAPSHOT.jar,file:/users/Darian/PredictionIO-0.9.6/lib/pio-assembly-0.9.6.jar), (spark.driver.extraClassPath,/users/Darian/PredictionIO-0.9.6/conf:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf), (spark.executorEnv.PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE,PGSQL), (spark.driver.memory,8G), (spark.executorEnv.PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS,9300), (spark.executorEnv.PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS,localhost), (spark.executorEnv.PIO_STORAGE_REPOSITORIES_MODELDATA_NAME,pio_model), (spark.executorEnv.PIO_STORAGE_SOURCES_HDFS_TYPE,hdfs), (spark.executorEnv.PIO_FS_BASEDIR,/Users/darian/.pio_store), (spark.executorEnv.PIO_STORAGE_SOURCES_HDFS_PATH,/Users/darian/.pio_store/models), (spark.executorEnv.PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE,PGSQL), (spark.executorEnv.PIO_STORAGE_SOURCES_LOCALFS_PATH,/Users/darian/.pio_store/models), (spark.executorEnv.PIO_HOME,/users/Darian/PredictionIO-0.9.6))
[INFO] [SparkContext] Running Spark version 1.5.1
[INFO] [SecurityManager] Changing view acls to: darian
[INFO] [SecurityManager] Changing modify acls to: darian
[INFO] [SecurityManager] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(darian); users with modify permissions: Set(darian)
[INFO] [Slf4jLogger] Slf4jLogger started
[INFO] [Remoting] Starting remoting
[INFO] [Remoting] Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.0.3:58504]
[INFO] [Utils] Successfully started service 'sparkDriver' on port 58504.
[INFO] [SparkEnv] Registering MapOutputTracker
[INFO] [SparkEnv] Registering BlockManagerMaster
[INFO] [DiskBlockManager] Created local directory at /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/blockmgr-9f246ab8-9bda-4072-8476-9119d780b742
[INFO] [MemoryStore] MemoryStore started with capacity 4.1 GB
[INFO] [HttpFileServer] HTTP File server directory is /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/httpd-38a322be-9bce-4faa-9626-915d8086b32a
[INFO] [HttpServer] Starting HTTP Server
[INFO] [Utils] Successfully started service 'HTTP file server' on port 58505.
[INFO] [SparkEnv] Registering OutputCommitCoordinator
[INFO] [Utils] Successfully started service 'SparkUI' on port 4040.
[INFO] [SparkUI] Started SparkUI at http://192.168.0.3:4040
[INFO] [SparkContext] Added JAR file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/target/scala-2.10/barebone-template-assembly-0.1-SNAPSHOT-deps.jar at http://192.168.0.3:58505/jars/barebone-template-assembly-0.1-SNAPSHOT-deps.jar with timestamp 1460680505604
[INFO] [SparkContext] Added JAR file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/target/scala-2.10/barebone-template_2.10-0.1-SNAPSHOT.jar at http://192.168.0.3:58505/jars/barebone-template_2.10-0.1-SNAPSHOT.jar with timestamp 1460680505611
[INFO] [SparkContext] Added JAR file:/users/Darian/PredictionIO-0.9.6/lib/pio-assembly-0.9.6.jar at http://192.168.0.3:58505/jars/pio-assembly-0.9.6.jar with timestamp 1460680505948
[INFO] [Utils] Copying /users/Darian/PredictionIO-0.9.6/conf/log4j.properties to /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/log4j.properties
[INFO] [SparkContext] Added file file:/users/Darian/PredictionIO-0.9.6/conf/log4j.properties at file:/users/Darian/PredictionIO-0.9.6/conf/log4j.properties with timestamp 1460680505949
[INFO] [Utils] Copying /users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf/hbase-site.xml to /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/hbase-site.xml
[INFO] [SparkContext] Added file file:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf/hbase-site.xml at file:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf/hbase-site.xml with timestamp 1460680505959
[WARN] [MetricsSystem] Using default name DAGScheduler for source because spark.app.id is not set.
[INFO] [Executor] Starting executor ID driver on host localhost
[DEBUG] [InternalLoggerFactory] Using SLF4J as the default logging framework
[DEBUG] [PlatformDependent0] java.nio.Buffer.address: available
[DEBUG] [PlatformDependent0] sun.misc.Unsafe.theUnsafe: available
[DEBUG] [PlatformDependent0] sun.misc.Unsafe.copyMemory: available
[DEBUG] [PlatformDependent0] java.nio.Bits.unaligned: true
[DEBUG] [PlatformDependent] Java version: 8
[DEBUG] [PlatformDependent] -Dio.netty.noUnsafe: false
[DEBUG] [PlatformDependent] sun.misc.Unsafe: available
[DEBUG] [PlatformDependent] -Dio.netty.noJavassist: false
[DEBUG] [PlatformDependent] Javassist: unavailable
[DEBUG] [PlatformDependent] You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
[DEBUG] [PlatformDependent] -Dio.netty.tmpdir: /var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T (java.io.tmpdir)
[DEBUG] [PlatformDependent] -Dio.netty.bitMode: 64 (sun.arch.data.model)
[DEBUG] [PlatformDependent] -Dio.netty.noPreferDirect: false
[DEBUG] [MultithreadEventLoopGroup] -Dio.netty.eventLoopThreads: 16
[DEBUG] [NioEventLoop] -Dio.netty.noKeySetOptimization: false
[DEBUG] [NioEventLoop] -Dio.netty.selectorAutoRebuildThreshold: 512
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@330c1f61
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@37d28f02
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@15efda6c
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@6056232d
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@33f2df51
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@107bfcb2
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@7bac686b
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@2ab26378
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.numHeapArenas: 16
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.numDirectArenas: 16
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.pageSize: 8192
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.maxOrder: 11
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.chunkSize: 16777216
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.tinyCacheSize: 512
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.smallCacheSize: 256
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.normalCacheSize: 64
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[DEBUG] [PooledByteBufAllocator] -Dio.netty.allocator.cacheTrimInterval: 8192
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@3ebe4ccc
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@6ed043d3
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@135a8c6f
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@6419a0e1
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@280d4882
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@44af588b
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@3d19d85
[TRACE] [NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.KQueueSelectorImpl@2ae62bb6
[DEBUG] [ThreadLocalRandom] -Dio.netty.initialSeedUniquifier: 0x06a8d68391cbdc68 (took 0 ms)
[DEBUG] [ByteBufUtil] -Dio.netty.allocator.type: unpooled
[DEBUG] [ByteBufUtil] -Dio.netty.threadLocalDirectBufferSize: 65536
[DEBUG] [NetUtil] Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[DEBUG] [NetUtil] /proc/sys/net/core/somaxconn: 128 (non-existent)
[INFO] [Utils] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58506.
[INFO] [NettyBlockTransferService] Server created on 58506
[INFO] [BlockManagerMaster] Trying to register BlockManager
[INFO] [BlockManagerMasterEndpoint] Registering block manager localhost:58506 with 4.1 GB RAM, BlockManagerId(driver, localhost, 58506)
[INFO] [BlockManagerMaster] Registered BlockManager
[INFO] [Engine$] EngineWorkflow.train
[INFO] [Engine$] DataSource: ucl.team10.anomaly.DataSource@322ba549
[INFO] [Engine$] Preparator: ucl.team10.anomaly.Preparator@64e1377c
[INFO] [Engine$] AlgorithmList: List(ucl.team10.anomaly.Algorithm@6a1ef65c)
[INFO] [Engine$] Data sanity check is on.
[INFO] [Engine$] org.apache.spark.rdd.MapPartitionsRDD does not support data sanity check. Skipping check.
[INFO] [Engine$] org.apache.spark.rdd.MapPartitionsRDD does not support data sanity check. Skipping check.
[INFO] [Engine$] org.apache.spark.rdd.MapPartitionsRDD does not support data sanity check. Skipping check.
[INFO] [Engine$] EngineWorkflow.train completed
[INFO] [Engine] engineInstanceId=1c9f0a71-e563-4ed1-8317-c27e3b795c80
[INFO] [SparkContext] Starting job: first at LAlgorithm.scala:118
[INFO] [DAGScheduler] Got job 0 (first at LAlgorithm.scala:118) with 1 output partitions
[INFO] [DAGScheduler] Final stage: ResultStage 0(first at LAlgorithm.scala:118)
[INFO] [DAGScheduler] Parents of final stage: List()
[INFO] [DAGScheduler] Missing parents: List()
[INFO] [DAGScheduler] Submitting ResultStage 0 (MapPartitionsRDD[3] at map at LAlgorithm.scala:45), which has no missing parents
[INFO] [MemoryStore] ensureFreeSpace(3800) called with curMem=0, maxMem=4445479895
[INFO] [MemoryStore] Block broadcast_0 stored as values in memory (estimated size 3.7 KB, free 4.1 GB)
[INFO] [MemoryStore] ensureFreeSpace(2132) called with curMem=3800, maxMem=4445479895
[INFO] [MemoryStore] Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.1 KB, free 4.1 GB)
[INFO] [BlockManagerInfo] Added broadcast_0_piece0 in memory on localhost:58506 (size: 2.1 KB, free: 4.1 GB)
[INFO] [SparkContext] Created broadcast 0 from broadcast at DAGScheduler.scala:861
[INFO] [DAGScheduler] Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at LAlgorithm.scala:45)
[INFO] [TaskSchedulerImpl] Adding task set 0.0 with 1 tasks
[INFO] [TaskSetManager] Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2467 bytes)
[INFO] [Executor] Running task 0.0 in stage 0.0 (TID 0)
[INFO] [Executor] Fetching file:/users/Darian/PredictionIO-0.9.6/conf/log4j.properties with timestamp 1460680505949
[INFO] [Utils] /users/Darian/PredictionIO-0.9.6/conf/log4j.properties has been previously copied to /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/log4j.properties
[INFO] [Executor] Fetching file:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf/hbase-site.xml with timestamp 1460680505959
[INFO] [Utils] /users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf/hbase-site.xml has been previously copied to /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/hbase-site.xml
[INFO] [Executor] Fetching http://192.168.0.3:58505/jars/barebone-template_2.10-0.1-SNAPSHOT.jar with timestamp 1460680505611
[INFO] [Utils] Fetching http://192.168.0.3:58505/jars/barebone-template_2.10-0.1-SNAPSHOT.jar to /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/fetchFileTemp2304170648779899127.tmp
[INFO] [Executor] Adding file:/private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/barebone-template_2.10-0.1-SNAPSHOT.jar to class loader
[INFO] [Executor] Fetching http://192.168.0.3:58505/jars/pio-assembly-0.9.6.jar with timestamp 1460680505948
[INFO] [Utils] Fetching http://192.168.0.3:58505/jars/pio-assembly-0.9.6.jar to /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/fetchFileTemp7727013817451883539.tmp
[INFO] [Executor] Adding file:/private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/pio-assembly-0.9.6.jar to class loader
[INFO] [Executor] Fetching http://192.168.0.3:58505/jars/barebone-template-assembly-0.1-SNAPSHOT-deps.jar with timestamp 1460680505604
[INFO] [Utils] Fetching http://192.168.0.3:58505/jars/barebone-template-assembly-0.1-SNAPSHOT-deps.jar to /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/fetchFileTemp9095993383631054529.tmp
[INFO] [Executor] Adding file:/private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b/userFiles-f4d02430-3f06-4507-83bf-3bcfcbeeaaa4/barebone-template-assembly-0.1-SNAPSHOT-deps.jar to class loader
[INFO] [Executor] Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
[INFO] [TaskSetManager] Finished task 0.0 in stage 0.0 (TID 0) in 495 ms on localhost (1/1)
[INFO] [TaskSchedulerImpl] Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] [DAGScheduler] ResultStage 0 (first at LAlgorithm.scala:118) finished in 0,505 s
[INFO] [DAGScheduler] Job 0 finished: first at LAlgorithm.scala:118, took 0,595705 s
[INFO] [SparkContext] Starting job: first at LAlgorithm.scala:118
[INFO] [DAGScheduler] Got job 1 (first at LAlgorithm.scala:118) with 4 output partitions
[INFO] [DAGScheduler] Final stage: ResultStage 1(first at LAlgorithm.scala:118)
[INFO] [DAGScheduler] Parents of final stage: List()
[INFO] [DAGScheduler] Missing parents: List()
[INFO] [DAGScheduler] Submitting ResultStage 1 (MapPartitionsRDD[3] at map at LAlgorithm.scala:45), which has no missing parents
[INFO] [MemoryStore] ensureFreeSpace(3800) called with curMem=5932, maxMem=4445479895
[INFO] [MemoryStore] Block broadcast_1 stored as values in memory (estimated size 3.7 KB, free 4.1 GB)
[INFO] [MemoryStore] ensureFreeSpace(2132) called with curMem=9732, maxMem=4445479895
[INFO] [MemoryStore] Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 4.1 GB)
[INFO] [BlockManagerInfo] Added broadcast_1_piece0 in memory on localhost:58506 (size: 2.1 KB, free: 4.1 GB)
[INFO] [SparkContext] Created broadcast 1 from broadcast at DAGScheduler.scala:861
[INFO] [DAGScheduler] Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at map at LAlgorithm.scala:45)
[INFO] [TaskSchedulerImpl] Adding task set 1.0 with 4 tasks
[INFO] [TaskSetManager] Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 2467 bytes)
[INFO] [TaskSetManager] Starting task 1.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2467 bytes)
[INFO] [TaskSetManager] Starting task 2.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2467 bytes)
[INFO] [TaskSetManager] Starting task 3.0 in stage 1.0 (TID 4, localhost, PROCESS_LOCAL, 2467 bytes)
[INFO] [Executor] Running task 0.0 in stage 1.0 (TID 1)
[INFO] [Executor] Running task 1.0 in stage 1.0 (TID 2)
[INFO] [Executor] Running task 2.0 in stage 1.0 (TID 3)
[INFO] [Executor] Running task 3.0 in stage 1.0 (TID 4)
[INFO] [Executor] Finished task 1.0 in stage 1.0 (TID 2). 915 bytes result sent to driver
[INFO] [Executor] Finished task 0.0 in stage 1.0 (TID 1). 915 bytes result sent to driver
[INFO] [Executor] Finished task 2.0 in stage 1.0 (TID 3). 915 bytes result sent to driver
[INFO] [Executor] Finished task 3.0 in stage 1.0 (TID 4). 915 bytes result sent to driver
[INFO] [TaskSetManager] Finished task 1.0 in stage 1.0 (TID 2) in 11 ms on localhost (1/4)
[INFO] [TaskSetManager] Finished task 3.0 in stage 1.0 (TID 4) in 11 ms on localhost (2/4)
[INFO] [TaskSetManager] Finished task 2.0 in stage 1.0 (TID 3) in 12 ms on localhost (3/4)
[INFO] [TaskSetManager] Finished task 0.0 in stage 1.0 (TID 1) in 14 ms on localhost (4/4)
[INFO] [DAGScheduler] ResultStage 1 (first at LAlgorithm.scala:118) finished in 0,015 s
[INFO] [TaskSchedulerImpl] Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] [DAGScheduler] Job 1 finished: first at LAlgorithm.scala:118, took 0,025380 s
[INFO] [SparkContext] Starting job: first at LAlgorithm.scala:118
[INFO] [DAGScheduler] Got job 2 (first at LAlgorithm.scala:118) with 3 output partitions
[INFO] [DAGScheduler] Final stage: ResultStage 2(first at LAlgorithm.scala:118)
[INFO] [DAGScheduler] Parents of final stage: List()
[INFO] [DAGScheduler] Missing parents: List()
[INFO] [DAGScheduler] Submitting ResultStage 2 (MapPartitionsRDD[3] at map at LAlgorithm.scala:45), which has no missing parents
[INFO] [MemoryStore] ensureFreeSpace(3800) called with curMem=11864, maxMem=4445479895
[INFO] [MemoryStore] Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 4.1 GB)
[INFO] [MemoryStore] ensureFreeSpace(2132) called with curMem=15664, maxMem=4445479895
[INFO] [MemoryStore] Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 4.1 GB)
[INFO] [BlockManagerInfo] Added broadcast_2_piece0 in memory on localhost:58506 (size: 2.1 KB, free: 4.1 GB)
[INFO] [SparkContext] Created broadcast 2 from broadcast at DAGScheduler.scala:861
[INFO] [DAGScheduler] Submitting 3 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at map at LAlgorithm.scala:45)
[INFO] [TaskSchedulerImpl] Adding task set 2.0 with 3 tasks
[INFO] [TaskSetManager] Starting task 0.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2467 bytes)
[INFO] [TaskSetManager] Starting task 1.0 in stage 2.0 (TID 6, localhost, PROCESS_LOCAL, 2467 bytes)
[INFO] [TaskSetManager] Starting task 2.0 in stage 2.0 (TID 7, localhost, PROCESS_LOCAL, 2472 bytes)
[INFO] [Executor] Running task 1.0 in stage 2.0 (TID 6)
[INFO] [Executor] Running task 0.0 in stage 2.0 (TID 5)
[INFO] [Executor] Running task 2.0 in stage 2.0 (TID 7)
[INFO] [Executor] Finished task 0.0 in stage 2.0 (TID 5). 915 bytes result sent to driver
[INFO] [Executor] Finished task 1.0 in stage 2.0 (TID 6). 915 bytes result sent to driver
[INFO] [TaskSetManager] Finished task 0.0 in stage 2.0 (TID 5) in 8 ms on localhost (1/3)
[INFO] [TaskSetManager] Finished task 1.0 in stage 2.0 (TID 6) in 8 ms on localhost (2/3)
[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   create table if not exists pio_meta_apps ( id serial not null primary key, name text not null, description text); (0 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCApps$$anonfun$1.apply(JDBCApps.scala:34)
    io.prediction.data.storage.jdbc.JDBCApps$$anonfun$1.apply(JDBCApps.scala:29)
    scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:222)
    scalikejdbc.DB.autoCommit(DB.scala:60)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:214)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.autoCommit(DB.scala:214)
    io.prediction.data.storage.jdbc.JDBCApps.<init>(JDBCApps.scala:29)
    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    java.lang.reflect.Constructor.newInstance(Constructor.java:408)
    io.prediction.data.storage.Storage$.getDataObject(Storage.scala:303)
    ...

[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   SELECT id, name, description FROM pio_meta_apps WHERE name = 'ESB'; (13 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCApps$$anonfun$5.apply(JDBCApps.scala:65)
    io.prediction.data.storage.jdbc.JDBCApps$$anonfun$5.apply(JDBCApps.scala:59)
    scalikejdbc.DBConnection$class.readOnly(DBConnection.scala:191)
    scalikejdbc.DB.readOnly(DB.scala:60)
    scalikejdbc.DB$$anonfun$readOnly$1.apply(DB.scala:173)
    scalikejdbc.DB$$anonfun$readOnly$1.apply(DB.scala:172)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.readOnly(DB.scala:172)
    io.prediction.data.storage.jdbc.JDBCApps.getByName(JDBCApps.scala:59)
    io.prediction.data.store.Common$.appNameToId(Common.scala:29)
    io.prediction.data.store.LEventStore$.find(LEventStore.scala:127)
    io.prediction.data.store.java.LJavaEventStore$.find(LJavaEventStore.scala:128)
    io.prediction.data.store.java.LJavaEventStore.find(LJavaEventStore.scala)
    ucl.team10.anomaly.DataSource.readTraining(DataSource.java:32)
    ...

[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   create table if not exists pio_meta_channels ( id serial not null primary key, name text not null, appid integer not null); (0 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCChannels$$anonfun$1.apply(JDBCChannels.scala:34)
    io.prediction.data.storage.jdbc.JDBCChannels$$anonfun$1.apply(JDBCChannels.scala:29)
    scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:222)
    scalikejdbc.DB.autoCommit(DB.scala:60)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:214)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.autoCommit(DB.scala:214)
    io.prediction.data.storage.jdbc.JDBCChannels.<init>(JDBCChannels.scala:29)
    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    java.lang.reflect.Constructor.newInstance(Constructor.java:408)
    io.prediction.data.storage.Storage$.getDataObject(Storage.scala:303)
    ...

[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   SELECT id, name, appid FROM pio_meta_channels WHERE appid = 7; (0 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCChannels$$anonfun$5.apply(JDBCChannels.scala:53)
    io.prediction.data.storage.jdbc.JDBCChannels$$anonfun$5.apply(JDBCChannels.scala:51)
    scalikejdbc.DBConnection$$anonfun$3.apply(DBConnection.scala:305)
    scalikejdbc.DBConnection$class.scalikejdbc$DBConnection$$rollbackIfThrowable(DBConnection.scala:274)
    scalikejdbc.DBConnection$class.localTx(DBConnection.scala:303)
    scalikejdbc.DB.localTx(DB.scala:60)
    scalikejdbc.DB$.localTx(DB.scala:257)
    io.prediction.data.storage.jdbc.JDBCChannels.getByAppid(JDBCChannels.scala:51)
    io.prediction.data.store.Common$$anonfun$appNameToId$1.apply(Common.scala:32)
    io.prediction.data.store.Common$$anonfun$appNameToId$1.apply(Common.scala:31)
    scala.Option.map(Option.scala:145)
    io.prediction.data.store.Common$.appNameToId(Common.scala:31)
    io.prediction.data.store.LEventStore$.find(LEventStore.scala:127)
    io.prediction.data.store.java.LJavaEventStore$.find(LJavaEventStore.scala:128)
    io.prediction.data.store.java.LJavaEventStore.find(LJavaEventStore.scala)
    ...

[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   select id, event, entityType, entityId, targetEntityType, targetEntityId, properties, eventTime, eventTimeZone, tags, prId, creationTime, creationTimeZone from pio_event_7 where entityType = 'user' and event = 'login' order by eventTime asc; (2 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCLEvents$$anonfun$futureFind$1$$anonfun$8.apply(JDBCLEvents.scala:219)
    io.prediction.data.storage.jdbc.JDBCLEvents$$anonfun$futureFind$1$$anonfun$8.apply(JDBCLEvents.scala:176)
    scalikejdbc.DBConnection$class.readOnly(DBConnection.scala:191)
    scalikejdbc.DB.readOnly(DB.scala:60)
    scalikejdbc.DB$$anonfun$readOnly$1.apply(DB.scala:173)
    scalikejdbc.DB$$anonfun$readOnly$1.apply(DB.scala:172)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.readOnly(DB.scala:172)
    io.prediction.data.storage.jdbc.JDBCLEvents$$anonfun$futureFind$1.apply(JDBCLEvents.scala:176)
    io.prediction.data.storage.jdbc.JDBCLEvents$$anonfun$futureFind$1.apply(JDBCLEvents.scala:176)
    scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
    scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
    scala.concurrent.impl.ExecutionContextImpl$$anon$3.exec(ExecutionContextImpl.scala:107)
    scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    ...

In algorithm
0.0 1:-0.2 2:-1.0 3:-0.5 4:0.111111 
0.0 1:1.0 2:-1.0 3:-1.0 4:-1.0 
0.0 1:-1.0 2:-1.0 3:0.25 4:-0.555556 
0.0 1:-0.6 2:-1.0 3:1.0 4:1.0 
..*
optimization finished, #iter = 8
obj = 0.9836608650190936, rho = 0.9836927146301698
nSV = 3, nBSV = 0
[INFO] [Executor] Finished task 2.0 in stage 2.0 (TID 7). 2407 bytes result sent to driver
[INFO] [TaskSetManager] Finished task 2.0 in stage 2.0 (TID 7) in 202 ms on localhost (3/3)
[INFO] [DAGScheduler] ResultStage 2 (first at LAlgorithm.scala:118) finished in 0,203 s
[INFO] [TaskSchedulerImpl] Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO] [DAGScheduler] Job 2 finished: first at LAlgorithm.scala:118, took 0,211345 s
[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   create table if not exists pio_meta_engineinstances ( id varchar(100) not null primary key, status text not null, startTime timestamp DEFAULT CURRENT_TIMESTAMP, endTime timestamp DEFAULT CURRENT_TIMESTAMP, engineId text not null, engineVersion text not null, engineVariant text not null, engineFactory text not null, batch text not null, env text not null, sparkConf text not null, datasourceParams text not null, preparatorParams text not null, algorithmsParams text not null, servingParams text not null); (1 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$1.apply(JDBCEngineInstances.scala:46)
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$1.apply(JDBCEngineInstances.scala:29)
    scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:222)
    scalikejdbc.DB.autoCommit(DB.scala:60)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:214)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.autoCommit(DB.scala:214)
    io.prediction.data.storage.jdbc.JDBCEngineInstances.<init>(JDBCEngineInstances.scala:29)
    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    java.lang.reflect.Constructor.newInstance(Constructor.java:408)
    io.prediction.data.storage.Storage$.getDataObject(Storage.scala:303)
    ...

[INFO] [CoreWorkflow$] Inserting persistent model
[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   create table if not exists pio_model_models ( id varchar(100) not null primary key, models bytea not null); (0 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCModels$$anonfun$1.apply(JDBCModels.scala:36)
    io.prediction.data.storage.jdbc.JDBCModels$$anonfun$1.apply(JDBCModels.scala:32)
    scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:222)
    scalikejdbc.DB.autoCommit(DB.scala:60)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:214)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.autoCommit(DB.scala:214)
    io.prediction.data.storage.jdbc.JDBCModels.<init>(JDBCModels.scala:32)
    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    java.lang.reflect.Constructor.newInstance(Constructor.java:408)
    io.prediction.data.storage.Storage$.getDataObject(Storage.scala:303)
    ...

[DEBUG] [StatementExecutor] The parameter([B@113f9078) is bound as an Object.
[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   insert into pio_model_models values('1c9f0a71-e563-4ed1-8317-c27e3b795c80', [B@113f9078); (1 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCModels$$anonfun$2.apply(JDBCModels.scala:40)
    io.prediction.data.storage.jdbc.JDBCModels$$anonfun$2.apply(JDBCModels.scala:39)
    scalikejdbc.DBConnection$$anonfun$3.apply(DBConnection.scala:305)
    scalikejdbc.DBConnection$class.scalikejdbc$DBConnection$$rollbackIfThrowable(DBConnection.scala:274)
    scalikejdbc.DBConnection$class.localTx(DBConnection.scala:303)
    scalikejdbc.DB.localTx(DB.scala:60)
    scalikejdbc.DB$.localTx(DB.scala:257)
    io.prediction.data.storage.jdbc.JDBCModels.insert(JDBCModels.scala:39)
    io.prediction.workflow.CoreWorkflow$.runTrain(CoreWorkflow.scala:77)
    io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:247)
    io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    java.lang.reflect.Method.invoke(Method.java:483)
    ...

[INFO] [CoreWorkflow$] Updating engine instance
[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   create table if not exists pio_meta_engineinstances ( id varchar(100) not null primary key, status text not null, startTime timestamp DEFAULT CURRENT_TIMESTAMP, endTime timestamp DEFAULT CURRENT_TIMESTAMP, engineId text not null, engineVersion text not null, engineVariant text not null, engineFactory text not null, batch text not null, env text not null, sparkConf text not null, datasourceParams text not null, preparatorParams text not null, algorithmsParams text not null, servingParams text not null); (1 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$1.apply(JDBCEngineInstances.scala:46)
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$1.apply(JDBCEngineInstances.scala:29)
    scalikejdbc.DBConnection$class.autoCommit(DBConnection.scala:222)
    scalikejdbc.DB.autoCommit(DB.scala:60)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:215)
    scalikejdbc.DB$$anonfun$autoCommit$1.apply(DB.scala:214)
    scalikejdbc.LoanPattern$class.using(LoanPattern.scala:18)
    scalikejdbc.DB$.using(DB.scala:138)
    scalikejdbc.DB$.autoCommit(DB.scala:214)
    io.prediction.data.storage.jdbc.JDBCEngineInstances.<init>(JDBCEngineInstances.scala:29)
    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    java.lang.reflect.Constructor.newInstance(Constructor.java:408)
    io.prediction.data.storage.Storage$.getDataObject(Storage.scala:303)
    ...

[DEBUG] [StatementExecutor$$anon$1] SQL execution completed

  [SQL Execution]
   update pio_meta_engineinstances set status = 'COMPLETED', startTime = '2016-04-15 03:35:04.059', endTime = '2016-04-15 03:35:07.521', engineId = 'ulP05G3N7mAwusAYQ5cN1hrLFaDS1xwp', engineVersion = 'd3b3dc43fd7f00c3c7d9ac56b2678b6ad6396624', engineVariant = 'default', engineFactory = 'ucl.team10.anomaly.AnomalyEngine', batch = '', env = 'PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_met... (1246)', sparkConf = 'spark.executor.extraClassPath=.', datasourceParams = '{"":{"appName":"ESB"}}', preparatorParams = '{"":{}}', algorithmsParams = '[{"algo":{"degree":3,"gamma":0.25,"coef0":0.0,"nu":0.5,"cache_size":100.0,"eps":0.001,"C":1.0,"p":0.... (148)', servingParams = '{"":{}}' where id = '1c9f0a71-e563-4ed1-8317-c27e3b795c80'; (1 ms)

  [Stack Trace]
    ...
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$9.apply(JDBCEngineInstances.scala:168)
    io.prediction.data.storage.jdbc.JDBCEngineInstances$$anonfun$9.apply(JDBCEngineInstances.scala:151)
    scalikejdbc.DBConnection$$anonfun$3.apply(DBConnection.scala:305)
    scalikejdbc.DBConnection$class.scalikejdbc$DBConnection$$rollbackIfThrowable(DBConnection.scala:274)
    scalikejdbc.DBConnection$class.localTx(DBConnection.scala:303)
    scalikejdbc.DB.localTx(DB.scala:60)
    scalikejdbc.DB$.localTx(DB.scala:257)
    io.prediction.data.storage.jdbc.JDBCEngineInstances.update(JDBCEngineInstances.scala:151)
    io.prediction.workflow.CoreWorkflow$.runTrain(CoreWorkflow.scala:83)
    io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:247)
    io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    java.lang.reflect.Method.invoke(Method.java:483)
    ...

[INFO] [CoreWorkflow$] Training completed successfully.
[DEBUG] [CoreWorkflow$] Stopping SparkContext
[INFO] [SparkUI] Stopped Spark web UI at http://192.168.0.3:4040
[INFO] [DAGScheduler] Stopping DAGScheduler
[INFO] [MapOutputTrackerMasterEndpoint] MapOutputTrackerMasterEndpoint stopped!
[INFO] [MemoryStore] MemoryStore cleared
[INFO] [BlockManager] BlockManager stopped
[INFO] [BlockManagerMaster] BlockManagerMaster stopped
[INFO] [OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] OutputCommitCoordinator stopped!
[INFO] [SparkContext] Successfully stopped SparkContext
[INFO] [RemoteActorRefProvider$RemotingTerminator] Shutting down remote daemon.
[INFO] [RemoteActorRefProvider$RemotingTerminator] Remote daemon shut down; proceeding with flushing remote transports.
[INFO] [ShutdownHookManager] Shutdown hook called
[INFO] [ShutdownHookManager] Deleting directory /private/var/folders/q8/2xqj5rx92x9gs2f39tr6jq8r0000gn/T/spark-3034ea50-ff06-4b7f-bade-e958a72fc36b
Training ended with return value 0 at Fri Apr 15 03:35:08 EEST 2016
[INFO] [Runner$] Submission command: /users/Darian/PredictionIO-0.9.6/vendors/spark-1.5.1/bin/spark-submit --executor-memory 16G --driver-memory 8G --total-executor-cores 4 --class io.prediction.workflow.CreateServer --jars file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/target/scala-2.10/barebone-template-assembly-0.1-SNAPSHOT-deps.jar,file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/target/scala-2.10/barebone-template_2.10-0.1-SNAPSHOT.jar --files file:/users/Darian/PredictionIO-0.9.6/conf/log4j.properties,file:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf/hbase-site.xml --driver-class-path /users/Darian/PredictionIO-0.9.6/conf:/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0/conf file:/users/Darian/PredictionIO-0.9.6/lib/pio-assembly-0.9.6.jar --engineInstanceId 1c9f0a71-e563-4ed1-8317-c27e3b795c80 --engine-variant file:/Users/darian/PredictionIO-0.9.6/templates/ANOMALY/engine.json --ip 0.0.0.0 --port 8001 --event-server-ip 0.0.0.0 --event-server-port 7070 --accesskey fPUWqKphOnC5woWp22lQUlLo6zAG8LNvyuugrQsSiM4Tavd8KCvs8LCld08Qqx61 --feedback --json-extractor Both --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_meta,PIO_FS_BASEDIR=/Users/darian/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/users/Darian/PredictionIO-0.9.6/vendors/hbase-1.0.0,PIO_HOME=/users/Darian/PredictionIO-0.9.6,PIO_FS_ENGINESDIR=/Users/darian/.pio_store/engines,PIO_STORAGE_SOURCES_LOCALFS_PATH=/Users/darian/.pio_store/models,PIO_STORAGE_SOURCES_PGSQL_URL=jdbc:postgresql://localhost/pio,PIO_STORAGE_SOURCES_HDFS_TYPE=hdfs,PIO_STORAGE_SOURCES_HDFS_PATH=/Users/darian/.pio_store/models,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=PGSQL,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=PGSQL,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=pio_event,PIO_STORAGE_SOURCES_PGSQL_PASSWORD=,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/users/Darian/PredictionIO-0.9.6/vendors/elasticsearch-1.4.4,PIO_STORAGE_SOURCES_PGSQL_TYPE=jdbc,PIO_FS_TMPDIR=/Users/darian/.pio_store/tmp,PIO_STORAGE_SOURCES_PGSQL_USERNAME=darian,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_model,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=PGSQL,PIO_CONF_DIR=/users/Darian/PredictionIO-0.9.6/conf,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs
[WARN] [WorkflowUtils$] Non-empty parameters supplied to ucl.team10.anomaly.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
[WARN] [WorkflowUtils$] Non-empty parameters supplied to ucl.team10.anomaly.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
[INFO] [Remoting] Starting remoting
[INFO] [Remoting] Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.0.3:58513]
[WARN] [MetricsSystem] Using default name DAGScheduler for source because spark.app.id is not set.
[INFO] [Engine] Using persisted model
[INFO] [Engine] Loaded model ucl.team10.anomaly.Model for algorithm ucl.team10.anomaly.Algorithm
[INFO] [MasterActor] Undeploying any existing engine instance at http://0.0.0.0:8001
[ERROR] [TcpListener] Bind failed for TCP channel on endpoint [/0.0.0.0:8001]
[WARN] [HttpListener] Bind to /0.0.0.0:8001 failed
[ERROR] [MasterActor] Bind failed. Retrying... (2 more trial(s))
[INFO] [HttpListener] Bound to /0.0.0.0:8001
[INFO] [MasterActor] Engine is deployed and running. Engine API is live at http://0.0.0.0:8001.
[INFO] [MasterActor] Stop server command received.
[INFO] [MasterActor] Server is shutting down.
Deploy ended with return value 0 at Fri Apr 15 05:45:55 EEST 2016
